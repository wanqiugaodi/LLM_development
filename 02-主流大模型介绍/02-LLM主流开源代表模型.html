
<!doctype html>
<html lang="zh" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="01-GPT%E7%B3%BB%E5%88%97%E6%A8%A1%E5%9E%8B.html">
      
      
        <link rel="next" href="../03-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B%E5%BA%94%E7%94%A8%E5%AE%9E%E6%88%98/01-%E5%A4%A7%E6%A8%A1%E5%9E%8BPrompt%E5%B7%A5%E7%A8%8B%E6%8C%87%E5%8D%97.html">
      
      
      <link rel="icon" href="../img/AI.jpg">
      <meta name="generator" content="mkdocs-1.6.0, mkdocs-material-9.5.24">
    
    
      
        <title>2.2 LLM主流开源代表模型 - 大模型技术开发与应用V5.0</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.6543a935.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    <body dir="ltr">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#1-llm" class="md-skip">
          跳转至
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="页眉">
    <a href=".." title="大模型技术开发与应用V5.0" class="md-header__button md-logo" aria-label="大模型技术开发与应用V5.0" data-md-component="logo">
      
  <img src="../img/AI.jpg" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            大模型技术开发与应用V5.0
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              2.2 LLM主流开源代表模型
            
          </span>
        </div>
      </div>
    </div>
    
    
      <script>var media,input,key,value,palette=__md_get("__palette");if(palette&&palette.color){"(prefers-color-scheme)"===palette.color.media&&(media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']"),palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent"));for([key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="搜索" placeholder="搜索" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="查找">
        
        <button type="reset" class="md-search__icon md-icon" title="清空当前内容" aria-label="清空当前内容" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            正在初始化搜索引擎
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="导航栏" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="大模型技术开发与应用V5.0" class="md-nav__button md-logo" aria-label="大模型技术开发与应用V5.0" data-md-component="logo">
      
  <img src="../img/AI.jpg" alt="logo">

    </a>
    大模型技术开发与应用V5.0
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_1" >
        
          
          <label class="md-nav__link" for="__nav_1" id="__nav_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    1:大模型背景简介
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_1">
            <span class="md-nav__icon md-icon"></span>
            1:大模型背景简介
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../01-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%83%8C%E6%99%AF%E7%AE%80%E4%BB%8B/01-LLM%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    1.1 LLM基础知识
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../01-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%83%8C%E6%99%AF%E7%AE%80%E4%BB%8B/02-LLM%E4%B8%BB%E8%A6%81%E7%B1%BB%E5%88%AB%E6%9E%B6%E6%9E%84.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    1.2 LLM主要架构类别
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" checked>
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    2:主流大模型介绍
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            2:主流大模型介绍
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="01-GPT%E7%B3%BB%E5%88%97%E6%A8%A1%E5%9E%8B.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2.1 GPT系列模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    2.2 LLM主流开源代表模型
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="02-LLM%E4%B8%BB%E6%B5%81%E5%BC%80%E6%BA%90%E4%BB%A3%E8%A1%A8%E6%A8%A1%E5%9E%8B.html" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    2.2 LLM主流开源代表模型
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#1-llm" class="md-nav__link">
    <span class="md-ellipsis">
      1 LLM主流大模型类别
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2-llama" class="md-nav__link">
    <span class="md-ellipsis">
      2 LLaMA模型
    </span>
  </a>
  
    <nav class="md-nav" aria-label="2 LLaMA模型">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#21" class="md-nav__link">
    <span class="md-ellipsis">
      2.1 训练目标
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#22" class="md-nav__link">
    <span class="md-ellipsis">
      2.2 模型结构
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#23" class="md-nav__link">
    <span class="md-ellipsis">
      2.3衍生应用
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#24" class="md-nav__link">
    <span class="md-ellipsis">
      2.4 迭代版本
    </span>
  </a>
  
    <nav class="md-nav" aria-label="2.4 迭代版本">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1-llama-120232" class="md-nav__link">
    <span class="md-ellipsis">
      1. Llama 1（2023年2月）
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2-llama-220237" class="md-nav__link">
    <span class="md-ellipsis">
      2. Llama 2（2023年7月）
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3-llama-320244" class="md-nav__link">
    <span class="md-ellipsis">
      3. Llama 3（2024年4月）
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#3-chatglm" class="md-nav__link">
    <span class="md-ellipsis">
      3 ChatGLM模型
    </span>
  </a>
  
    <nav class="md-nav" aria-label="3 ChatGLM模型">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#31" class="md-nav__link">
    <span class="md-ellipsis">
      3.1 训练目标
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#32" class="md-nav__link">
    <span class="md-ellipsis">
      3.2 模型结构
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#33" class="md-nav__link">
    <span class="md-ellipsis">
      3.3 迭代版本
    </span>
  </a>
  
    <nav class="md-nav" aria-label="3.3 迭代版本">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1-glm-130b20228" class="md-nav__link">
    <span class="md-ellipsis">
      1. GLM-130B（2022年8月）
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2-chatglm-6b20233" class="md-nav__link">
    <span class="md-ellipsis">
      2. ChatGLM-6B（2023年3月）
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3-chatglm2-6b20236" class="md-nav__link">
    <span class="md-ellipsis">
      3. ChatGLM2-6B（2023年6月）
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#4-chatglm3-6b20239" class="md-nav__link">
    <span class="md-ellipsis">
      4. ChatGLM3-6B（2023年9月）
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#5-glm-4-20241" class="md-nav__link">
    <span class="md-ellipsis">
      5. GLM-4 系列（2024年1月）
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#4-baichuan" class="md-nav__link">
    <span class="md-ellipsis">
      4 Baichuan模型
    </span>
  </a>
  
    <nav class="md-nav" aria-label="4 Baichuan模型">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#41" class="md-nav__link">
    <span class="md-ellipsis">
      4.1 训练目标
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#42" class="md-nav__link">
    <span class="md-ellipsis">
      4.2 模型结构
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#43" class="md-nav__link">
    <span class="md-ellipsis">
      4.3 迭代版本
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#4-qwen" class="md-nav__link">
    <span class="md-ellipsis">
      4 Qwen模型
    </span>
  </a>
  
    <nav class="md-nav" aria-label="4 Qwen模型">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#41_1" class="md-nav__link">
    <span class="md-ellipsis">
      4.1 训练目标
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#41_2" class="md-nav__link">
    <span class="md-ellipsis">
      4.1 模型结构
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#42_1" class="md-nav__link">
    <span class="md-ellipsis">
      4.2 迭代版本
    </span>
  </a>
  
    <nav class="md-nav" aria-label="4.2 迭代版本">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1-qwen1520238" class="md-nav__link">
    <span class="md-ellipsis">
      1. Qwen1.5（2023年8月）
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2-qwen220241" class="md-nav__link">
    <span class="md-ellipsis">
      2. Qwen2（2024年1月）
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3-qwen2520251" class="md-nav__link">
    <span class="md-ellipsis">
      3. Qwen2.5（2025年1月）
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#5" class="md-nav__link">
    <span class="md-ellipsis">
      5.零一万物
    </span>
  </a>
  
    <nav class="md-nav" aria-label="5.零一万物">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#51" class="md-nav__link">
    <span class="md-ellipsis">
      5.1 训练目标
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#52" class="md-nav__link">
    <span class="md-ellipsis">
      5.2 模型结构
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#53" class="md-nav__link">
    <span class="md-ellipsis">
      5.3 迭代版本
    </span>
  </a>
  
    <nav class="md-nav" aria-label="5.3 迭代版本">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1-yi-34b202311" class="md-nav__link">
    <span class="md-ellipsis">
      1 Yi-34B（2023年11月）
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2-yi-15-20245" class="md-nav__link">
    <span class="md-ellipsis">
      2 Yi-1.5 系列（2024年5月）
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3-yi-coder20249" class="md-nav__link">
    <span class="md-ellipsis">
      3 Yi-Coder（2024年9月）
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#6deepseek" class="md-nav__link">
    <span class="md-ellipsis">
      6.deepseek模型
    </span>
  </a>
  
    <nav class="md-nav" aria-label="6.deepseek模型">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#61" class="md-nav__link">
    <span class="md-ellipsis">
      6.1 模型版本
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#62" class="md-nav__link">
    <span class="md-ellipsis">
      6.2 模型结构
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#31-multi-head-latent-attention-mla" class="md-nav__link">
    <span class="md-ellipsis">
      3.1 多头注意力 Multi-head Latent Attention (MLA)¶
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#32-moe" class="md-nav__link">
    <span class="md-ellipsis">
      3.2 混合专家(MoE)架构¶
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#33-fp8" class="md-nav__link">
    <span class="md-ellipsis">
      3.3 FP8 高效能使用记忆体¶
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#63" class="md-nav__link">
    <span class="md-ellipsis">
      6.3 训练策略
    </span>
  </a>
  
    <nav class="md-nav" aria-label="6.3 训练策略">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1v3" class="md-nav__link">
    <span class="md-ellipsis">
      1.V3的训练流程
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2-r1" class="md-nav__link">
    <span class="md-ellipsis">
      2 R1的训练流程
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#7" class="md-nav__link">
    <span class="md-ellipsis">
      7.开源协议
    </span>
  </a>
  
    <nav class="md-nav" aria-label="7.开源协议">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#71mit" class="md-nav__link">
    <span class="md-ellipsis">
      7.1MIT 协议
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#72-apache-20" class="md-nav__link">
    <span class="md-ellipsis">
      7.2 Apache 2.0 协议
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#73-llama-meta" class="md-nav__link">
    <span class="md-ellipsis">
      7.3 Llama 系列协议（Meta 定制）
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#74-mcpmodel-context-protocol" class="md-nav__link">
    <span class="md-ellipsis">
      7.4 MCP（Model Context Protocol）协议
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_1" class="md-nav__link">
    <span class="md-ellipsis">
      小结总结
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    3:大模型提示词工程应用实战
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            3:大模型提示词工程应用实战
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../03-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B%E5%BA%94%E7%94%A8%E5%AE%9E%E6%88%98/01-%E5%A4%A7%E6%A8%A1%E5%9E%8BPrompt%E5%B7%A5%E7%A8%8B%E6%8C%87%E5%8D%97.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    3.1 大模型Prompt工程指南
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../03-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B%E5%BA%94%E7%94%A8%E5%AE%9E%E6%88%98/02-%E9%87%91%E8%9E%8D%E8%A1%8C%E4%B8%9A%E5%8A%A8%E6%80%81%E6%96%B9%E5%90%91%E8%AF%84%E4%BC%B0%E9%A1%B9%E7%9B%AE%E4%BB%8B%E7%BB%8D.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    3.2 金融行业动态方向评估项目介绍
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../03-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B%E5%BA%94%E7%94%A8%E5%AE%9E%E6%88%98/03-LLM%E5%AE%9E%E7%8E%B0%E9%87%91%E8%9E%8D%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    3.3 LLM实现金融文本分类
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../03-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B%E5%BA%94%E7%94%A8%E5%AE%9E%E6%88%98/04-LLM%E5%AE%9E%E7%8E%B0%E9%87%91%E8%9E%8D%E6%96%87%E6%9C%AC%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    3.4 LLM实现金融文本信息抽取
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../03-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B%E5%BA%94%E7%94%A8%E5%AE%9E%E6%88%98/05-LLM%E5%AE%9E%E7%8E%B0%E9%87%91%E8%9E%8D%E6%96%87%E6%9C%AC%E5%8C%B9%E9%85%8D.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    3.5 LLM实现金融文本匹配
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" >
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    4:大模型微调主要方式
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            4:大模型微调主要方式
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../04-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E4%B8%BB%E8%A6%81%E6%96%B9%E5%BC%8F/01-%E5%A4%A7%E6%A8%A1%E5%9E%8BPrompt-Tuning%E6%96%B9%E6%B3%95.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    4.1 大模型Prompt-Tuning方法
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../04-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E4%B8%BB%E8%A6%81%E6%96%B9%E5%BC%8F/02-%E5%A4%A7%E6%A8%A1%E5%9E%8BPEFT%E5%BE%AE%E8%B0%83%E6%96%B9%E6%B3%95.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    4.2 大模型PEFT微调方法
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" >
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    5:基于GPT2预训练模型搭建医疗问诊机器人
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            5:基于GPT2预训练模型搭建医疗问诊机器人
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../05-%E5%9F%BA%E4%BA%8EGPT2%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E6%90%AD%E5%BB%BA%E5%8C%BB%E7%96%97%E9%97%AE%E8%AF%8A%E6%9C%BA%E5%99%A8%E4%BA%BA/01-%E5%8C%BB%E7%96%97%E9%97%AE%E8%AF%8A%E6%9C%BA%E5%99%A8%E4%BA%BA%E5%AE%9E%E7%8E%B0.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    5.1 医疗问诊机器人实现
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6" >
        
          
          <label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    6:新零售行业评价决策系统
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6">
            <span class="md-nav__icon md-icon"></span>
            6:新零售行业评价决策系统
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../06-%E6%96%B0%E9%9B%B6%E5%94%AE%E8%A1%8C%E4%B8%9A%E8%AF%84%E4%BB%B7%E5%86%B3%E7%AD%96%E7%B3%BB%E7%BB%9F/01-%E9%A1%B9%E7%9B%AE%E8%83%8C%E6%99%AF%E4%BB%8B%E7%BB%8D.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    6.1 项目背景介绍
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../06-%E6%96%B0%E9%9B%B6%E5%94%AE%E8%A1%8C%E4%B8%9A%E8%AF%84%E4%BB%B7%E5%86%B3%E7%AD%96%E7%B3%BB%E7%BB%9F/02-BERT%2BPET%E6%96%B9%E5%BC%8F%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%BB%8B%E7%BB%8D.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    6.2 BERT+PET方式文本分类介绍
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../06-%E6%96%B0%E9%9B%B6%E5%94%AE%E8%A1%8C%E4%B8%9A%E8%AF%84%E4%BB%B7%E5%86%B3%E7%AD%96%E7%B3%BB%E7%BB%9F/03-BERT%2BPET%E6%96%B9%E5%BC%8F%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E4%BB%8B%E7%BB%8D.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    6.3 BERT+PET方式数据预处理
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../06-%E6%96%B0%E9%9B%B6%E5%94%AE%E8%A1%8C%E4%B8%9A%E8%AF%84%E4%BB%B7%E5%86%B3%E7%AD%96%E7%B3%BB%E7%BB%9F/04-BERT%2BPET%E6%96%B9%E5%BC%8F%E6%A8%A1%E5%9E%8B%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0%E4%B8%8E%E8%AE%AD%E7%BB%83.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    6.4 BERT+PET方式模型代码实现和训练
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../06-%E6%96%B0%E9%9B%B6%E5%94%AE%E8%A1%8C%E4%B8%9A%E8%AF%84%E4%BB%B7%E5%86%B3%E7%AD%96%E7%B3%BB%E7%BB%9F/05-BERT%2BP-Tuning%E6%96%B9%E5%BC%8F%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%BB%8B%E7%BB%8D.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    6.5 BERT+P-Tuning方式文本分类介绍
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../06-%E6%96%B0%E9%9B%B6%E5%94%AE%E8%A1%8C%E4%B8%9A%E8%AF%84%E4%BB%B7%E5%86%B3%E7%AD%96%E7%B3%BB%E7%BB%9F/06-BERT%2BP-Tuning%E6%96%B9%E5%BC%8F%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E4%BB%8B%E7%BB%8D.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    6.6 BERT+P-Tuning方式数据预处理
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../06-%E6%96%B0%E9%9B%B6%E5%94%AE%E8%A1%8C%E4%B8%9A%E8%AF%84%E4%BB%B7%E5%86%B3%E7%AD%96%E7%B3%BB%E7%BB%9F/07-BERT%2BP-Tuning%E6%96%B9%E5%BC%8F%E6%A8%A1%E5%9E%8B%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0%E4%B8%8E%E8%AE%AD%E7%BB%83.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    6.7 BERT+P-Tuning方式模型代码实现和训练
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7" >
        
          
          <label class="md-nav__link" for="__nav_7" id="__nav_7_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    7:基于ChatGLM微调实现信息抽取+文本分类的多任务实战
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7">
            <span class="md-nav__icon md-icon"></span>
            7:基于ChatGLM微调实现信息抽取+文本分类的多任务实战
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../07-%E5%9F%BA%E4%BA%8EChatGLM%E5%BE%AE%E8%B0%83%E5%AE%9E%E7%8E%B0%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%2B%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E7%9A%84%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AE%9E%E6%88%98/01-%E9%A1%B9%E7%9B%AE%E6%95%B4%E4%BD%93%E4%BB%8B%E7%BB%8D.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    7.1 项目整体简介
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../07-%E5%9F%BA%E4%BA%8EChatGLM%E5%BE%AE%E8%B0%83%E5%AE%9E%E7%8E%B0%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%2B%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E7%9A%84%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AE%9E%E6%88%98/02-%E5%A4%9A%E4%BB%BB%E5%8A%A1%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    7.2 多任务数据预处理方式
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../07-%E5%9F%BA%E4%BA%8EChatGLM%E5%BE%AE%E8%B0%83%E5%AE%9E%E7%8E%B0%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%2B%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E7%9A%84%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AE%9E%E6%88%98/03-LoRA%E6%96%B9%E5%BC%8F%E6%A8%A1%E5%9E%8B%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0%E4%B8%8E%E8%AE%AD%E7%BB%83.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    7.3 LoRA方式微调ChatGLM模型代码实现和训练
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../07-%E5%9F%BA%E4%BA%8EChatGLM%E5%BE%AE%E8%B0%83%E5%AE%9E%E7%8E%B0%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%2B%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E7%9A%84%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AE%9E%E6%88%98/%E8%B6%8B%E5%8A%A8%E4%BA%91%E4%BD%BF%E7%94%A8%E3%80%8A%E8%A1%A5%E5%85%85%E3%80%8B.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    7.4 趋动云使用《扩展》
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_8" >
        
          
          <label class="md-nav__link" for="__nav_8" id="__nav_8_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    8:基于LangChain+ChatGLM-6B实现本地知识RAG问答机器人
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_8_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_8">
            <span class="md-nav__icon md-icon"></span>
            8:基于LangChain+ChatGLM-6B实现本地知识RAG问答机器人
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../08-%E5%9F%BA%E4%BA%8ELangChain%2BChatGLM%E5%AE%9E%E7%8E%B0%E6%9C%AC%E5%9C%B0%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94%E6%9C%BA%E5%99%A8%E4%BA%BA/01-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E6%A1%86%E6%9E%B6LangChain%E8%AF%A6%E8%A7%A3.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    8.1 LangChain介绍
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../08-%E5%9F%BA%E4%BA%8ELangChain%2BChatGLM%E5%AE%9E%E7%8E%B0%E6%9C%AC%E5%9C%B0%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94%E6%9C%BA%E5%99%A8%E4%BA%BA/02-LangChain%20%2B%20ChatGLM%20%E5%AE%9E%E7%8E%B0%E6%9C%AC%E5%9C%B0%E7%9F%A5%E8%AF%86%E5%BA%93%E9%97%AE%E7%AD%94.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    8.2 LangChain+ChatGLM-6B实现本地知识库问答
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_9" >
        
          
          <label class="md-nav__link" for="__nav_9" id="__nav_9_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    9:大模型Agent的应用
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_9_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_9">
            <span class="md-nav__icon md-icon"></span>
            9:大模型Agent的应用
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../09-%E5%A4%A7%E6%A8%A1%E5%9E%8BAgent%E5%BA%94%E7%94%A8/01-%E5%A4%A7%E6%A8%A1%E5%9E%8BFunction%20Call%E7%9A%84%E5%8E%9F%E7%90%86%E5%8F%8A%E5%85%B6%E5%BA%94%E7%94%A8.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    9.1 大模型functioncall的原理及其应用
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../09-%E5%A4%A7%E6%A8%A1%E5%9E%8BAgent%E5%BA%94%E7%94%A8/02-GPTs%E7%9A%84%E5%8E%9F%E7%90%86%E5%8F%8A%E5%BA%94%E7%94%A8.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    9.2 GPTs的原理及应用
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../09-%E5%A4%A7%E6%A8%A1%E5%9E%8BAgent%E5%BA%94%E7%94%A8/03-Assistant%20API%E7%9A%84%E5%8E%9F%E7%90%86%E5%8F%8A%E5%BA%94%E7%94%A8.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    9.3 Assistant API的原理及应用
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../09-%E5%A4%A7%E6%A8%A1%E5%9E%8BAgent%E5%BA%94%E7%94%A8/04-Agent%E5%8E%9F%E7%90%86%E4%BB%8B%E7%BB%8D%E4%B8%8E%E5%BA%94%E7%94%A8.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    9.4 Agent原理介绍与应用
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#1-llm" class="md-nav__link">
    <span class="md-ellipsis">
      1 LLM主流大模型类别
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2-llama" class="md-nav__link">
    <span class="md-ellipsis">
      2 LLaMA模型
    </span>
  </a>
  
    <nav class="md-nav" aria-label="2 LLaMA模型">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#21" class="md-nav__link">
    <span class="md-ellipsis">
      2.1 训练目标
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#22" class="md-nav__link">
    <span class="md-ellipsis">
      2.2 模型结构
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#23" class="md-nav__link">
    <span class="md-ellipsis">
      2.3衍生应用
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#24" class="md-nav__link">
    <span class="md-ellipsis">
      2.4 迭代版本
    </span>
  </a>
  
    <nav class="md-nav" aria-label="2.4 迭代版本">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1-llama-120232" class="md-nav__link">
    <span class="md-ellipsis">
      1. Llama 1（2023年2月）
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2-llama-220237" class="md-nav__link">
    <span class="md-ellipsis">
      2. Llama 2（2023年7月）
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3-llama-320244" class="md-nav__link">
    <span class="md-ellipsis">
      3. Llama 3（2024年4月）
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#3-chatglm" class="md-nav__link">
    <span class="md-ellipsis">
      3 ChatGLM模型
    </span>
  </a>
  
    <nav class="md-nav" aria-label="3 ChatGLM模型">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#31" class="md-nav__link">
    <span class="md-ellipsis">
      3.1 训练目标
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#32" class="md-nav__link">
    <span class="md-ellipsis">
      3.2 模型结构
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#33" class="md-nav__link">
    <span class="md-ellipsis">
      3.3 迭代版本
    </span>
  </a>
  
    <nav class="md-nav" aria-label="3.3 迭代版本">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1-glm-130b20228" class="md-nav__link">
    <span class="md-ellipsis">
      1. GLM-130B（2022年8月）
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2-chatglm-6b20233" class="md-nav__link">
    <span class="md-ellipsis">
      2. ChatGLM-6B（2023年3月）
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3-chatglm2-6b20236" class="md-nav__link">
    <span class="md-ellipsis">
      3. ChatGLM2-6B（2023年6月）
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#4-chatglm3-6b20239" class="md-nav__link">
    <span class="md-ellipsis">
      4. ChatGLM3-6B（2023年9月）
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#5-glm-4-20241" class="md-nav__link">
    <span class="md-ellipsis">
      5. GLM-4 系列（2024年1月）
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#4-baichuan" class="md-nav__link">
    <span class="md-ellipsis">
      4 Baichuan模型
    </span>
  </a>
  
    <nav class="md-nav" aria-label="4 Baichuan模型">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#41" class="md-nav__link">
    <span class="md-ellipsis">
      4.1 训练目标
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#42" class="md-nav__link">
    <span class="md-ellipsis">
      4.2 模型结构
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#43" class="md-nav__link">
    <span class="md-ellipsis">
      4.3 迭代版本
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#4-qwen" class="md-nav__link">
    <span class="md-ellipsis">
      4 Qwen模型
    </span>
  </a>
  
    <nav class="md-nav" aria-label="4 Qwen模型">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#41_1" class="md-nav__link">
    <span class="md-ellipsis">
      4.1 训练目标
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#41_2" class="md-nav__link">
    <span class="md-ellipsis">
      4.1 模型结构
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#42_1" class="md-nav__link">
    <span class="md-ellipsis">
      4.2 迭代版本
    </span>
  </a>
  
    <nav class="md-nav" aria-label="4.2 迭代版本">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1-qwen1520238" class="md-nav__link">
    <span class="md-ellipsis">
      1. Qwen1.5（2023年8月）
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2-qwen220241" class="md-nav__link">
    <span class="md-ellipsis">
      2. Qwen2（2024年1月）
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3-qwen2520251" class="md-nav__link">
    <span class="md-ellipsis">
      3. Qwen2.5（2025年1月）
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#5" class="md-nav__link">
    <span class="md-ellipsis">
      5.零一万物
    </span>
  </a>
  
    <nav class="md-nav" aria-label="5.零一万物">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#51" class="md-nav__link">
    <span class="md-ellipsis">
      5.1 训练目标
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#52" class="md-nav__link">
    <span class="md-ellipsis">
      5.2 模型结构
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#53" class="md-nav__link">
    <span class="md-ellipsis">
      5.3 迭代版本
    </span>
  </a>
  
    <nav class="md-nav" aria-label="5.3 迭代版本">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1-yi-34b202311" class="md-nav__link">
    <span class="md-ellipsis">
      1 Yi-34B（2023年11月）
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2-yi-15-20245" class="md-nav__link">
    <span class="md-ellipsis">
      2 Yi-1.5 系列（2024年5月）
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3-yi-coder20249" class="md-nav__link">
    <span class="md-ellipsis">
      3 Yi-Coder（2024年9月）
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#6deepseek" class="md-nav__link">
    <span class="md-ellipsis">
      6.deepseek模型
    </span>
  </a>
  
    <nav class="md-nav" aria-label="6.deepseek模型">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#61" class="md-nav__link">
    <span class="md-ellipsis">
      6.1 模型版本
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#62" class="md-nav__link">
    <span class="md-ellipsis">
      6.2 模型结构
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#31-multi-head-latent-attention-mla" class="md-nav__link">
    <span class="md-ellipsis">
      3.1 多头注意力 Multi-head Latent Attention (MLA)¶
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#32-moe" class="md-nav__link">
    <span class="md-ellipsis">
      3.2 混合专家(MoE)架构¶
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#33-fp8" class="md-nav__link">
    <span class="md-ellipsis">
      3.3 FP8 高效能使用记忆体¶
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#63" class="md-nav__link">
    <span class="md-ellipsis">
      6.3 训练策略
    </span>
  </a>
  
    <nav class="md-nav" aria-label="6.3 训练策略">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1v3" class="md-nav__link">
    <span class="md-ellipsis">
      1.V3的训练流程
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2-r1" class="md-nav__link">
    <span class="md-ellipsis">
      2 R1的训练流程
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#7" class="md-nav__link">
    <span class="md-ellipsis">
      7.开源协议
    </span>
  </a>
  
    <nav class="md-nav" aria-label="7.开源协议">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#71mit" class="md-nav__link">
    <span class="md-ellipsis">
      7.1MIT 协议
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#72-apache-20" class="md-nav__link">
    <span class="md-ellipsis">
      7.2 Apache 2.0 协议
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#73-llama-meta" class="md-nav__link">
    <span class="md-ellipsis">
      7.3 Llama 系列协议（Meta 定制）
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#74-mcpmodel-context-protocol" class="md-nav__link">
    <span class="md-ellipsis">
      7.4 MCP（Model Context Protocol）协议
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_1" class="md-nav__link">
    <span class="md-ellipsis">
      小结总结
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


  <h1>2.2 LLM主流开源代表模型</h1>

<p>LLM主流开源大模型介绍</p>
<h2 id="1-llm">1 LLM主流大模型类别<a class="headerlink" href="#1-llm" title="Permanent link">&para;</a></h2>
<p>随着ChatGPT迅速火爆，引发了大模型的时代变革，国内外各大公司也快速跟进生成式AI市场，近百款大模型发布及应用。</p>
<p>目前，比较流行的开源的大语言模型主要以下几种：</p>
<ul>
<li>
<p>LLaMA大模型</p>
</li>
<li>
<p>ChatGLM大模型</p>
</li>
<li>Qwen大模型</li>
<li>01万物大模型</li>
<li>deepseek的模型</li>
</ul>
<p>以下是针对 <strong>7B、13B、32B、70B、304B</strong> 参数规模的本地大模型硬件配置参考表，结合量化技术（4-bit/8-bit）和不同场景需求分类整理：</p>
<table>
<thead>
<tr>
<th style="text-align: left;">模型大小</th>
<th style="text-align: left;">训练显存需求</th>
<th style="text-align: left;">推理显存需求</th>
<th style="text-align: left;">CPU内存需求</th>
<th style="text-align: left;">计算资源</th>
<th style="text-align: left;">训练时间</th>
<th style="text-align: left;">多GPU需求</th>
<th style="text-align: left;">推荐使用场景</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><strong>7B</strong></td>
<td style="text-align: left;">20-24GB (单卡)</td>
<td style="text-align: left;">10-14GB (FP16)</td>
<td style="text-align: left;">16-32GB</td>
<td style="text-align: left;">单卡（A100/A6000）</td>
<td style="text-align: left;">数天至数周</td>
<td style="text-align: left;">可选（单卡/双卡）</td>
<td style="text-align: left;">中小企业应用部署</td>
</tr>
<tr>
<td style="text-align: left;"><strong>13B</strong></td>
<td style="text-align: left;">40-48GB (双卡)</td>
<td style="text-align: left;">20-26GB (FP16)</td>
<td style="text-align: left;">32-64GB</td>
<td style="text-align: left;">双卡（A100 40G）</td>
<td style="text-align: left;">1-2周</td>
<td style="text-align: left;">双卡以上</td>
<td style="text-align: left;">企业级应用、中等负载任务</td>
</tr>
<tr>
<td style="text-align: left;"><strong>32B</strong></td>
<td style="text-align: left;">160-200GB (多卡)</td>
<td style="text-align: left;">64-70GB (FP16)</td>
<td style="text-align: left;">64-128GB</td>
<td style="text-align: left;">4-8卡（A100/H100）</td>
<td style="text-align: left;">2-4周</td>
<td style="text-align: left;">必需（4+卡）</td>
<td style="text-align: left;">复杂NLP任务、云端服务</td>
</tr>
<tr>
<td style="text-align: left;"><strong>70B</strong></td>
<td style="text-align: left;">400GB+ (多卡集群)</td>
<td style="text-align: left;">140GB+ (FP16)</td>
<td style="text-align: left;">128-256GB</td>
<td style="text-align: left;">8-16卡（H100集群）</td>
<td style="text-align: left;">1-3个月</td>
<td style="text-align: left;">必需（16+卡）</td>
<td style="text-align: left;">超大规模任务、行业解决方案</td>
</tr>
<tr>
<td style="text-align: left;"><strong>304B更大</strong></td>
<td style="text-align: left;">1.5TB+ (分布式)</td>
<td style="text-align: left;">600GB+ (需量化)</td>
<td style="text-align: left;">512GB+</td>
<td style="text-align: left;">数百卡（超算集群）</td>
<td style="text-align: left;">数月以上</td>
<td style="text-align: left;">必需（百卡级）</td>
<td style="text-align: left;">国家/科研级超级计算</td>
</tr>
</tbody>
</table>
<hr />
<h2 id="2-llama">2 LLaMA模型<a class="headerlink" href="#2-llama" title="Permanent link">&para;</a></h2>
<p>LLaMA（Large Language Model Meta AI），由 Meta AI 于2023年发布的一个开放且高效的大型基础语言模型，共有 7B、13B、33B、65B（650 亿）四种版本。</p>
<p>LLaMA是由Meta AI发布的大语言系列模型，完整的名字是Large Language Model Meta AI。Llama这个单词本身是指美洲大羊驼，所以社区也将这个系列的模型昵称为羊驼系模型。</p>
<p>LLaMA训练数据是以英语为主的拉丁语系，另外还包含了来自 GitHub 的代码数据。训练数据以英文为主，不包含中韩日文，所有训练数据都是开源的。其中LLaMA-65B 和 LLaMA-33B 是在 1.4万亿 (1.4T) 个 token上训练的，而最小的模型 LLaMA-7B 和LLaMA-13B 是在 1万亿 (1T) 个 token 上训练的。</p>
<h3 id="21">2.1 训练目标<a class="headerlink" href="#21" title="Permanent link">&para;</a></h3>
<p>在**训练目标**上，LLaMA 的训练目标是语言模型，即根据已有的上文去预测下一个词。</p>
<p>关于**tokenizer**，LLaMA 的训练语料以英文为主，使用了BPE分词算法作为 tokenizer，词表大小只有 32000。词表里的中文 token 很少，只有几百个，LLaMA tokenizer 对中文分词的编码效率比较低。</p>
<h3 id="22">2.2 模型结构<a class="headerlink" href="#22" title="Permanent link">&para;</a></h3>
<p>和 GPT 系列一样，LLaMA 模型也是 Decoder-only架构，但结合前人的工作做了一些改进，比如：</p>
<ul>
<li><strong>Pre-normalization</strong>：为了提高训练稳定性，没有使用传统的 post layer norm，而是使用了 pre layer Norm，同时使用 RMSNorm归一化函数（RMS Norm的主要区别在于去掉了减去均值的部分，简化了Layer Norm 的计算，可以在减少约 7%∼64% 的计算时间）。</li>
</ul>
<div align=center><img src="./assets/2-2-5.png" style="zoom:60%" ><img/></div>

<ul>
<li><strong>激活函数</strong>：将 ReLU 非线性替换为 SwiGLU 激活函数。</li>
</ul>
<p><img alt="image-20250401091714678" src="assets/image-20250401091714678.png" /></p>
<ul>
<li><strong>位置编码</strong>：去除了绝对位置编码，采用了旋转位置编码 RoPE。</li>
</ul>
<p><img alt="image-20250401094132657" src="assets/image-20250401094132657.png" /></p>
<p>对于 token 序列中的每个词嵌入向量，首先计算其对应的 query 和 key 向量，然后对每个 token 位置都计算对应的旋转位置编码，接着对每个 token 位置的 query 和 key 向量的元素按照**两两一组**应用旋转变换，最后再计算 query 和 key 之间的内积得到 self-attention 的计算结果。</p>
<p>角度的设置：</p>
<p><img alt="image-20250401094540848" src="assets/image-20250401094540848.png" /></p>
<h3 id="23">2.3衍生应用<a class="headerlink" href="#23" title="Permanent link">&para;</a></h3>
<p><img alt="Llama-1 变体模型" src="assets/202409041255444.jpg" /></p>
<ul>
<li>Alpaca: 斯坦福大学在 52k 条英文指令遵循数据集上微调了 7B 规模的 LLaMA。</li>
<li>Vicuna: 加州大学伯克利分校在 ShareGPT 收集的用户共享对话数据上，微调了 13B 规模的 LLaMA。</li>
<li>BELLE: 链家仅使用由 ChatGPT 生产的数据，对 LLaMA 进行了指令微调，并针对中文进行了优化。</li>
<li>Chinese LLaMA：</li>
<li>扩充中文词表：常见做法：在中文语料上使用 Sentence Piece 训练一个中文 tokenizer，使用了 20000 个中文词汇。然后将中文 tokenizer 与原始的 LLaMA tokenizer 合并起来，通过组合二者的词汇表，最终获得一个合并的 tokenizer，称为 Chinese LLaMA tokenizer。词表大小为 49953。</li>
</ul>
<h3 id="24">2.4 迭代版本<a class="headerlink" href="#24" title="Permanent link">&para;</a></h3>
<h4 id="1-llama-120232"><strong>1. Llama 1（2023年2月）</strong><a class="headerlink" href="#1-llama-120232" title="Permanent link">&para;</a></h4>
<p>Llama 1 是 Meta 推出的首个开源大语言模型系列，包含 <strong>7B、13B、30B 和 65B</strong> 四种参数规模。其核心创新包括：<br />
- <strong>架构改进</strong>：基于 Transformer 结构，引入 <strong>SwiGLU 激活函数</strong> 和 <strong>RMSNorm 归一化</strong>，提升训练稳定性；<br />
- <strong>位置编码</strong>：采用 <strong>RoPE（旋转位置编码）</strong>，增强模型对长文本位置信息的捕捉能力；<br />
- <strong>训练数据</strong>：使用约 <strong>1.4 万亿 token</strong> 的公开数据集训练，但上下文长度限制在 <strong>2048 token</strong>；<br />
- <strong>开源限制</strong>：仅限研究用途，不可商用。  </p>
<p>Llama 1 为后续版本奠定了技术基础，但推理效率和对齐能力仍有不足。  </p>
<h4 id="2-llama-220237"><strong>2. Llama 2（2023年7月）</strong><a class="headerlink" href="#2-llama-220237" title="Permanent link">&para;</a></h4>
<p>Llama 2 是首个支持 <strong>免费商用</strong> 的版本，参数规模扩展为 <strong>7B、13B、34B 和 70B</strong>，主要改进包括：  ； 
- <strong>上下文窗口</strong>：长度翻倍至 <strong>4096 token</strong>，支持更长的文本理解和生成；<br />
- <strong>对齐优化</strong>：推出 <strong>Chat 版本</strong>，通过 RLHF（人类反馈强化学习）优化对话能力；<br />
- <strong>训练数据</strong>：数据量增至 <strong>2 万亿 token</strong>，覆盖更多语言和领域。  </p>
<p>Llama 2 成为开源社区的重要选择，尤其在对话和通用任务中表现优异。  </p>
<h4 id="3-llama-320244"><strong>3. Llama 3（2024年4月）</strong><a class="headerlink" href="#3-llama-320244" title="Permanent link">&para;</a></h4>
<p>Llama 3 进一步提升了性能和通用性，已发布 <strong>8B 和 70B</strong> 、 <strong>405B</strong> 超大规模模型：<br />
- <strong>分词器升级</strong>：改用 <strong>TikToken 分词器</strong>（词表 128K），提升编码效率和多语言支持；<br />
- <strong>训练数据</strong>：数据规模暴增至 <strong>15 万亿 token 以上</strong>（是 Llama 2 的 7 倍），涵盖更高质量内容；<br />
- <strong>上下文长度</strong>：支持 <strong>8192 token</strong>，并可扩展至更长文本；<br />
- <strong>推理优化</strong>：在指令跟随、代码生成等任务中表现显著提升。  </p>
<p>Llama 3 完全开源可商用，且未来也可能整合多模态能力。  </p>
<h2 id="3-chatglm">3 ChatGLM模型<a class="headerlink" href="#3-chatglm" title="Permanent link">&para;</a></h2>
<p>ChatGLM 是清华大学提出的一个开源、支持中英双语的对话语言模型。该模型使用了和 ChatGPT 相似的技术，经过约 1T 标识符的中英双语训练(中英文比例为 1:1)，辅以监督微调、反馈自助、人类反馈强化学习等技术的加持，62 亿参数的 ChatGLM-6B 已经能生成相当符合人类偏好的回答。</p>
<h3 id="31">3.1 训练目标<a class="headerlink" href="#31" title="Permanent link">&para;</a></h3>
<p>GLM是一种基于自回归空白填充目标的通用预训练框架。GLM 将 NLU 任务转化为包含任务描述的完形填空问题，可以通过自回归生成的方式来回答。自回归空白填充目标是指在输入文本中随机挖去一些连续的文本片段，然后训练模型按照任意顺序重建这些片段。完形填空问题是指在输入文本中用一个特殊的符号（如[MASK]）替换掉一个或多个词，然后训练模型预测被替换掉的词。</p>
<div align=center><img src="./assets/2-2-1.png" style="zoom:60%" ><img/></div>

<hr />
<p>上图说明了GLM的实现思想（训练目标）：</p>
<ol>
<li>原始文本 <span class="arithmatex"><span class="MathJax_Preview">x=[x_1, x_2,...,x_6]</span><script type="math/tex">x=[x_1, x_2,...,x_6]</script></span>随机进行连续 mask，这里假设 mask 掉<span class="arithmatex"><span class="MathJax_Preview">[x_3]</span><script type="math/tex">[x_3]</script></span>和 <span class="arithmatex"><span class="MathJax_Preview">[x_5,x_6]</span><script type="math/tex">[x_5,x_6]</script></span> （GLM-130B中，mask两种类型：短语和长短落或文章）.</li>
<li>将<span class="arithmatex"><span class="MathJax_Preview">[x_3]</span><script type="math/tex">[x_3]</script></span>和 <span class="arithmatex"><span class="MathJax_Preview">[x_5,x_6]</span><script type="math/tex">[x_5,x_6]</script></span> 替换为 [M] 标志，并打乱 Part B 的顺序。为了捕捉跨度之间的内在联系，随机交换跨度的顺序。</li>
<li>GLM 自回归地生成 Part B。 每个片段在输入时前面加上 [S]，在输出时后面加上 [E]。 二维位置编码表示不同片段之间和片段内部的位置关系。</li>
<li>自注意力掩码。 灰色区域被掩盖。Part A 的词语可以自我看到（图蓝色框），但不能看到 Part B。 Part B 的词语可以看到 Part A 和 Part B 中的前面的词语（图黄色和绿色框对应两个片段）。 [M] := [MASK]，[S] := [START]，[E] := [END]</li>
</ol>
<blockquote>
<p>注意：</p>
<ul>
<li>
<p>Position1 和 Position2 是输入的二维编码，第一个维度表示片段在原始文本中的相对位置，第二个维度表示片段内部的相对位置。</p>
</li>
<li>
<p>假设原始文本是  <span class="arithmatex"><span class="MathJax_Preview">x=[x_1, x_2,...,x_6]</span><script type="math/tex">x=[x_1, x_2,...,x_6]</script></span>，其中<span class="arithmatex"><span class="MathJax_Preview">[x_3]</span><script type="math/tex">[x_3]</script></span>和 <span class="arithmatex"><span class="MathJax_Preview">[x_5,x_6]</span><script type="math/tex">[x_5,x_6]</script></span> 被挖去。那么，被挖去的片段在第一个维度上的位置编码就是它们在原始文本中的索引，即<span class="arithmatex"><span class="MathJax_Preview">[x_3]</span><script type="math/tex">[x_3]</script></span>来自片段 3，<span class="arithmatex"><span class="MathJax_Preview">[x_5,x_6]</span><script type="math/tex">[x_5,x_6]</script></span> 来自片段 5。在第二个维度上的位置编码就是它们在片段中的索引。因此， <span class="arithmatex"><span class="MathJax_Preview">x_3</span><script type="math/tex">x_3</script></span>的二维位置编码是[3, 2]， <span class="arithmatex"><span class="MathJax_Preview">x_5</span><script type="math/tex">x_5</script></span>的二维位置编码是[5, 2]，<span class="arithmatex"><span class="MathJax_Preview">x_6</span><script type="math/tex">x_6</script></span> 的二维编码是[5, 3]。</p>
</li>
<li>
<p>同样，我们可以得到<span class="arithmatex"><span class="MathJax_Preview">x_1</span><script type="math/tex">x_1</script></span>的二维位置编码是[1, 0]， <span class="arithmatex"><span class="MathJax_Preview">x_2</span><script type="math/tex">x_2</script></span>的位置编码是[2, 0]， <span class="arithmatex"><span class="MathJax_Preview">x_4</span><script type="math/tex">x_4</script></span>的位置编码是[4, 0]。</p>
</li>
</ul>
</blockquote>
<hr />
<h3 id="32">3.2 模型结构<a class="headerlink" href="#32" title="Permanent link">&para;</a></h3>
<p>采用transformer的decoder模块，因为无论是对于自然语言理解还是自然语言生成类任务，GLM都是看成生成任务做。但是这里只能说类deocder, 因为decoder是单向的，但是GLM某些位置可以看到双向的，因此又被称为Prefix -Decoder.</p>
<p>相比原始Decoder模块，模型结构有如下改动点：</p>
<ul>
<li><strong>embedding 层梯度缩减</strong>：为了提升训练稳定性，减小了 embedding 层的梯度。梯度缩减的效果相当于把 embedding 层的梯度缩小了 10 倍，减小了梯度的范数。</li>
<li><strong>layer normalization</strong>：采用了基于 Deep Norm 的 post layer norm。</li>
<li><strong>激活函数</strong>：替换ReLU激活函数采用了 GeGLU 激活函数。</li>
<li><strong>位置编码</strong>：去除了绝对位置编码，采用了旋转位置编码 RoPE。</li>
</ul>
<h3 id="33">3.3 迭代版本<a class="headerlink" href="#33" title="Permanent link">&para;</a></h3>
<p><img alt="img" src="assets/v2-29798c7c091559c24307ebd0ee52bf9f_1440w.jpg" /></p>
<h4 id="1-glm-130b20228"><strong>1. GLM-130B（2022年8月）</strong><a class="headerlink" href="#1-glm-130b20228" title="Permanent link">&para;</a></h4>
<ul>
<li>采用 <strong>GLM 架构</strong>（自回归填空目标），不同于 GPT 和 BERT 的纯自回归或自编码模式。</li>
<li>在 <strong>HELM 评测</strong> 中表现与 GPT-3（davinci）相当。</li>
<li>支持 <strong>多任务学习</strong>，适用于多种 NLP 任务。</li>
<li>开源，成为当时亚洲唯一入选斯坦福大学大模型评测的千亿级模型。</li>
</ul>
<h4 id="2-chatglm-6b20233"><strong>2. ChatGLM-6B（2023年3月）</strong><a class="headerlink" href="#2-chatglm-6b20233" title="Permanent link">&para;</a></h4>
<ul>
<li>针对 <strong>中文优化</strong>，支持中英双语对话。</li>
<li>采用 <strong>监督微调（SFT）+ 人类反馈强化学习（RLHF）</strong> 进行对齐。</li>
<li>可在 消费级显卡上运行，极大降低推理门槛。</li>
<li>开源后迅速成为 Hugging Face 热门模型，下载量超 1000 万次。</li>
</ul>
<h4 id="3-chatglm2-6b20236"><strong>3. ChatGLM2-6B（2023年6月）</strong><a class="headerlink" href="#3-chatglm2-6b20236" title="Permanent link">&para;</a></h4>
<ul>
<li>在 <strong>MMLU、GSM8K、BBH</strong> 等评测中性能显著提升（如 MMLU +23%）。</li>
<li>推出 <strong>CodeGeeX2-6B</strong>，代码生成能力大幅增强。</li>
</ul>
<h4 id="4-chatglm3-6b20239"><strong>4. ChatGLM3-6B（2023年9月）</strong><a class="headerlink" href="#4-chatglm3-6b20239" title="Permanent link">&para;</a></h4>
<ul>
<li>支持 <strong>函数调用</strong> 和 <strong>代码解释器</strong>，增强复杂任务处理能力。</li>
<li>在 <strong>42 个基准测试</strong>（语义、数学、推理等）中表现优异。</li>
<li>进一步优化 <strong>长文本理解</strong> 和 <strong>多轮对话</strong> 能力。</li>
</ul>
<h4 id="5-glm-4-20241"><strong>5. GLM-4 系列（2024年1月）</strong><a class="headerlink" href="#5-glm-4-20241" title="Permanent link">&para;</a></h4>
<ul>
<li><strong>GLM-4（基座模型）</strong>：</li>
<li>支持 <strong>128K 上下文</strong>，性能对标 GPT-4。</li>
<li>在 <strong>MMLU、GSM8K、HumanEval</strong> 等评测中接近或超越 GPT-4。</li>
<li><strong>GLM-4-9B（开源版）</strong>：</li>
<li>支持 <strong>1M（100万）上下文</strong>，优于 Llama-3-8B。</li>
</ul>
<h2 id="4-baichuan">4 Baichuan模型<a class="headerlink" href="#4-baichuan" title="Permanent link">&para;</a></h2>
<p>Baichuan-7B由百川智能于2023年6月发布的一个开放且可商用的大型预训练语言模型，其支持中英双语，是在约 1.2万亿 (1.2T) 个 token上训练的70亿参数模型。</p>
<h3 id="41">4.1 训练目标<a class="headerlink" href="#41" title="Permanent link">&para;</a></h3>
<p>在**训练目标**上，Baichuan-7B 的训练目标也是语言模型，即根据已有的上文去预测下一个词。</p>
<p>关于**tokenizer**，使用了BPE分词算法作为 tokenizer，词表大小64000。</p>
<p>关于**数据**，原始数据包括开源的中英文数据和自行抓取的中文互联网数据，以及部分高质量知识性数据。</p>
<h3 id="42">4.2 模型结构<a class="headerlink" href="#42" title="Permanent link">&para;</a></h3>
<p>和 LLaMA 一样的模型设计，也是 Decoder-only架构，但结合前人的工作做了一些改进，比如：</p>
<ul>
<li>
<p><strong>Pre-normalization</strong>：为了提高训练稳定性，没有使用传统的 post layer norm，而是使用了 pre layer Norm，同时使用 RMSNorm归一化函数。</p>
</li>
<li>
<p><strong>激活函数</strong>：使用 SwiGLU 激活函数。</p>
</li>
<li>
<p><strong>位置编码</strong>：采用了旋转位置编码 RoPE。</p>
</li>
</ul>
<h3 id="43">4.3 迭代版本<a class="headerlink" href="#43" title="Permanent link">&para;</a></h3>
<ul>
<li><strong>Baichuan-7B</strong>（2023年6月）</li>
<li>百川智能的首款开源模型，70亿参数，支持中英文。</li>
<li>训练数据1.4万亿token，上下文窗口2048 tokens。</li>
<li>在多个基准测试（如C-EVAL、MMLU）上超越同规模开源模型9。</li>
<li><strong>Baichuan-13B</strong>（2023年7月）</li>
<li>130亿参数，训练数据量超过LLaMA-13B 40%。</li>
<li>采用ALiBi位置编码，支持4096 tokens上下文。</li>
<li>在中文评测（如C-EVAL）上超越ChatGPT（部分领域）</li>
</ul>
<h2 id="4-qwen">4 Qwen模型<a class="headerlink" href="#4-qwen" title="Permanent link">&para;</a></h2>
<p>通义千问是由阿里云自主研发的大模型，用于理解和分析用户输入的自然语言，以及图片、音频、视频等多模态数据。</p>
<h3 id="41_1">4.1 训练目标<a class="headerlink" href="#41_1" title="Permanent link">&para;</a></h3>
<p>Qwen不仅仅是一个语言模型，而是一个致力于实现通用人工智能（AGI）的项目，目前包含了大型语言模型（LLM）和大型多模态模型（LMM）。下图展示了Qwen的主要组成部分:</p>
<p><img alt="img" src="assets/family.png" /></p>
<h3 id="41_2">4.1 模型结构<a class="headerlink" href="#41_2" title="Permanent link">&para;</a></h3>
<p>Qwen模型也是 Decoder-only架构，但结合前人的工作做了一些改进，比如：</p>
<ul>
<li><strong>位置编码</strong>：使用 <strong>RoPE（Rotary Positional Embedding）</strong>，增强长文本建模能力。</li>
<li><strong>归一化层</strong>：采用 <strong>RMSNorm</strong>，替代传统 LayerNorm，提升训练稳定性。</li>
<li><strong>激活函数</strong>：使用 <strong>SwiGLU</strong>，相比 GeLU 能更好地提取特征。</li>
</ul>
<h3 id="42_1">4.2 迭代版本<a class="headerlink" href="#42_1" title="Permanent link">&para;</a></h3>
<h4 id="1-qwen1520238"><strong>1. Qwen1.5（2023年8月）</strong><a class="headerlink" href="#1-qwen1520238" title="Permanent link">&para;</a></h4>
<ul>
<li>基于 <strong>Transformer 架构</strong>，采用 <strong>RoPE 位置编码</strong> 和 <strong>SwiGLU 激活函数</strong>。</li>
<li>支持 <strong>32K 长上下文</strong>，优化多语言能力（12 种语言）。</li>
<li>引入 <strong>分组查询注意力（GQA）</strong>（仅大模型），降低推理显存占用5。</li>
</ul>
<h4 id="2-qwen220241"><strong>2. Qwen2（2024年1月）</strong><a class="headerlink" href="#2-qwen220241" title="Permanent link">&para;</a></h4>
<ul>
<li><strong>全系支持 GQA</strong>，推理效率提升。</li>
<li><strong>上下文扩展至 128K</strong>，增强长文本处理能力。</li>
<li><strong>训练数据增至 7 万亿 token</strong>，优化数学、代码能力7。</li>
</ul>
<h4 id="3-qwen2520251"><strong>3. Qwen2.5（2025年1月）</strong><a class="headerlink" href="#3-qwen2520251" title="Permanent link">&para;</a></h4>
<ul>
<li><strong>Qwen2.5-1M</strong>：首个支持 <strong>百万 Tokens（1M）</strong> 上下文的大模型，处理速度 <strong>超越 GPT-4o-mini 7 倍</strong>。</li>
<li><strong>稀疏注意力 + 长度外推</strong>：使 32K 训练模型适应 1M 任务4。</li>
<li><strong>多模态版本 Qwen2.5-VL</strong>：</li>
<li>支持 <strong>图像、视频、文本</strong> 联合理解。</li>
<li>72B 版本在 <strong>视觉问答、文档解析</strong> 任务领先8。</li>
</ul>
<h2 id="5">5.零一万物<a class="headerlink" href="#5" title="Permanent link">&para;</a></h2>
<p>零一万物（01.AI）是由李开复博士于2023年创立的人工智能公司，专注于 <strong>大语言模型（LLM）</strong> 的研发与应用，致力于打造 <strong>世界级开源与闭源大模型</strong>，并推动 AI 2.0 的商业化落地。。</p>
<h3 id="51">5.1 训练目标<a class="headerlink" href="#51" title="Permanent link">&para;</a></h3>
<p>专注于中文场景优化，图文对，是中英双语的，提升多语言、多模态的能力</p>
<p><img alt="image-20250401112036851" src="assets/image-20250401112036851.png" /></p>
<h3 id="52">5.2 模型结构<a class="headerlink" href="#52" title="Permanent link">&para;</a></h3>
<p>Yi 的模型结构与 LLaMA  的模型结构基本一致，没有太大的改变：</p>
<ul>
<li><strong>核心结构</strong>：采用 <strong>Decoder-Only</strong>，适用于自回归文本生成。</li>
<li><strong>位置编码</strong>：使用 <strong>RoPE（Rotary Positional Embedding）</strong>，增强长文本建模能力。</li>
<li><strong>归一化层</strong>：采用 <strong>RMSNorm</strong>（Root Mean Square Layer Normalization），提升训练稳定性。</li>
</ul>
<h3 id="53">5.3 迭代版本<a class="headerlink" href="#53" title="Permanent link">&para;</a></h3>
<p>开源的模型：</p>
<h4 id="1-yi-34b202311"><strong>1 Yi-34B（2023年11月）</strong><a class="headerlink" href="#1-yi-34b202311" title="Permanent link">&para;</a></h4>
<ul>
<li>零一万物的首个开源大模型，支持 <strong>中英双语</strong>，性能对标 LLaMA-2 34B。</li>
<li>在 <strong>AlpacaEval 2.0</strong> 等国际评测中表现优异2。</li>
</ul>
<h4 id="2-yi-15-20245"><strong>2 Yi-1.5 系列（2024年5月）</strong><a class="headerlink" href="#2-yi-15-20245" title="Permanent link">&para;</a></h4>
<ul>
<li><strong>升级版本</strong>：包括 Yi-6B、Yi-9B、Yi-34B</li>
<li>优化 <strong>推理效率</strong> 和 <strong>多轮对话能力</strong>。</li>
<li>在 <strong>Hugging Face、魔搭社区</strong> 开源，吸引全球开发者。</li>
</ul>
<h4 id="3-yi-coder20249"><strong>3  Yi-Coder（2024年9月）</strong><a class="headerlink" href="#3-yi-coder20249" title="Permanent link">&para;</a></h4>
<ul>
<li>
<p>提供 <strong>1.5B、9B</strong> 版本，支持 <strong>52种编程语言</strong>。</p>
</li>
<li>
<p><strong>128K 上下文窗口</strong>，适用于复杂代码项目。</p>
</li>
</ul>
<h2 id="6deepseek">6.deepseek模型<a class="headerlink" href="#6deepseek" title="Permanent link">&para;</a></h2>
<h3 id="61">6.1 模型版本<a class="headerlink" href="#61" title="Permanent link">&para;</a></h3>
<p><strong>DeepSeek-V3</strong>：生成式大模型：包含6710亿个参数，其中370亿个活跃参数，并采用专家混合（MoE）架构，将模型划分为专门处理数学和编码等任务的组件，以减轻训练负担。</p>
<p><strong>DeepSeek-R1</strong>：推理型大模型，经历了多个微调和RL阶段，包括拒绝采样和第二轮RL训练，以提高其通用能力和与人类偏好的一致性。</p>
<p><img alt="image-20250401120028324" src="assets/image-20250401120028324.png" /></p>
<p><strong>蒸馏DeepSeek模型</strong>：DeepSeek开发了较小的、蒸馏版的DeepSeek-R1，参数范围从15亿到700亿，将先进的推理能力带到较弱的硬件上</p>
<p><img alt="image-20250401115853710" src="assets/image-20250401115853710.png" /></p>
<h3 id="62">6.2 模型结构<a class="headerlink" href="#62" title="Permanent link">&para;</a></h3>
<p>DeepSeek 的技术核心是「大语言模型」（LLM），类似于 OpenAI 的 GPT 或 Google 的 BERT，但他们更专注于实现 AGI，让 AI 变得更通用、更智能。这意味着他们的技术不仅能处理语言，未来还能应用在更多领域，比如医疗诊断、金融分析、教育辅助等，DeepSeek 为了让电脑在处理大量资料时，能够更省记忆体、更快运算，并且适合处理复杂的任务，比如长篇文章或多轮对话，所以使用了以下技术。</p>
<h3 id="31-multi-head-latent-attention-mla">3.1 <strong>多头注意力 Multi-head Latent Attention (MLA)</strong><a href="#31-multi-head-latent-attention-mla">¶</a><a class="headerlink" href="#31-multi-head-latent-attention-mla" title="Permanent link">&para;</a></h3>
<ul>
<li><strong>目标</strong>：让电脑处理很长的文字时，减少记忆体的使用，并且加快处理速度。</li>
<li><strong>方法</strong>：透过一种叫做「低秩因子分解(Low-Rank Factorization)」的技术，把需要记住的资料变小，这样记忆体需求就降低了。例如，原本需要很多记忆体，现在可以减少30%。</li>
<li><strong>应用</strong>：适合处理很长的文章或对话，比如法律文件或多轮对话。</li>
</ul>
<p><img alt="image-20250401121509866" src="assets/image-20250401121509866.png" /></p>
<h3 id="32-moe">3.2 <strong>混合专家(MoE)架构</strong><a href="#32-moe">¶</a><a class="headerlink" href="#32-moe" title="Permanent link">&para;</a></h3>
<ul>
<li><strong>目标</strong>：让电脑在处理复杂任务时更有效率。</li>
<li><strong>方法</strong>：DeepSeek 用了一种叫「混合专家模型」（MoE）的技术，简单来说，就是让电脑在处理任务时，不需要动用全部的资源，只启动一部分来工作就好。举个例子，DeepSeek 的 R1 模型虽然总共有 6710 亿个参数（可以想像成它的「脑容量」很大），但每次处理任务时，只会用到其中大约 370 亿个参数。</li>
<li><strong>特点</strong>：这样的好处是，电脑跑得更快，而且还更省电、更省钱。</li>
</ul>
<p><img alt="image-20250401121525914" src="assets/image-20250401121525914.png" /></p>
<h3 id="33-fp8">3.3 <strong>FP8 高效能使用记忆体</strong><a href="#33-fp8">¶</a><a class="headerlink" href="#33-fp8" title="Permanent link">&para;</a></h3>
<ul>
<li><strong>目标</strong>：让电脑在训练模型时，减少记忆体使用并加快运算速度。</li>
<li><strong>方法</strong>：DeepSeek 用了 FP8 混合精度训练框架，这个技术比传统的 FP16 和 FP32 更省记忆体，让训练和推理的速度更快、效率更高。</li>
<li><strong>通讯优化</strong>：在多个 GPU 之间传输资料时，使用一种叫做「DualPipe」的技术，让资料传输更顺畅，减少等待时间，提升整体效率。</li>
</ul>
<p><img alt="image-20250401121545454" src="assets/image-20250401121545454.png" /></p>
<h3 id="63">6.3 训练策略<a class="headerlink" href="#63" title="Permanent link">&para;</a></h3>
<h4 id="1v3">1.V3的训练流程<a class="headerlink" href="#1v3" title="Permanent link">&para;</a></h4>
<p>DeepSeek的R1是以V3为基础构建的（冷启动）。如果想深入理解R1的训练，就要先看V3的训练流程。V3的训练包括预训练（含基础预训练和上下文长度扩展）、后训练三个阶段。</p>
<p>在预训练阶段后，对<a href="https://zhida.zhihu.com/search?content_id=253373233&amp;content_type=Article&amp;match_order=1&amp;q=DeepSeek-V3&amp;zhida_source=entity">DeepSeek-V3</a> 进行了两次上下文长度扩展，第一阶段将最大上下文长度扩展到32K，第二阶段进一步扩展到128K。然后在 DeepSeek-V3的基础模型上进行包括有监督精调 (<a href="https://zhida.zhihu.com/search?content_id=253373233&amp;content_type=Article&amp;match_order=1&amp;q=SFT&amp;zhida_source=entity">SFT</a>) 和强化学习(RL)在内的后训练，使其更贴近人类的偏好。</p>
<p><img alt="image-20250401122229963" src="assets/image-20250401122229963.png" /></p>
<h4 id="2-r1">2 R1的训练流程<a class="headerlink" href="#2-r1" title="Permanent link">&para;</a></h4>
<p>DeepSeek-R1 的训练过程分为4个阶段，包括使用数千高质量CoT示例进行SFT的冷启动，面向推理的强化学习，通过拒绝抽样的SFT，面向全场景任务的强化学习与对齐。</p>
<p><img alt="image-20250406113801214" src="assets/image-20250406113801214.png" /></p>
<p><img alt="image-20250401122354006" src="assets/image-20250401122354006.png" /></p>
<h2 id="7">7.开源协议<a class="headerlink" href="#7" title="Permanent link">&para;</a></h2>
<p>大模型的开源协议是决定模型使用权限、商业应用范围及二次开发限制的重要法律框架。不同开源协议在自由度、署名要求、商用许可等方面存在显著差异。</p>
<h3 id="71mit">7.1MIT 协议<a class="headerlink" href="#71mit" title="Permanent link">&para;</a></h3>
<ul>
<li><strong>特点</strong>：最宽松的开源协议之一，允许自由使用、修改、分发，包括商业用途，仅需保留版权声明和许可声明。</li>
<li><strong>代表模型</strong>：DeepSeek 采用 MIT 协议，允许用户自由商用，甚至可“套壳”销售1。</li>
<li><strong>优势</strong>：最大化开放生态，吸引广泛开发者参与。</li>
</ul>
<h3 id="72-apache-20">7.2 Apache 2.0 协议<a class="headerlink" href="#72-apache-20" title="Permanent link">&para;</a></h3>
<ul>
<li><strong>特点</strong>：类似 MIT，但额外包含专利授权条款，防止专利诉讼风险。要求修改后的代码需明确标注变更。</li>
<li><strong>代表模型</strong>：</li>
<li>xAI 的 <strong>Grok-1</strong>（3140B 参数，全球最大开源模型之一）。</li>
<li>阿里的 <strong>Qwen 系列</strong>（部分模型）。</li>
<li>蚂蚁集团的 <strong>Ling-Coder-Lite</strong>（MoE 架构代码模型）。</li>
</ul>
<h3 id="73-llama-meta">7.3 Llama 系列协议（Meta 定制）<a class="headerlink" href="#73-llama-meta" title="Permanent link">&para;</a></h3>
<ul>
<li><strong>特点</strong>：</li>
<li>允许中小企业和个人商用，但月活超 7 亿的巨头需单独谈判许可。</li>
<li>禁止使用 Llama 生成的数据训练其他竞争模型（如非 Llama 衍生品）。</li>
<li><strong>代表模型</strong>：Meta 的 <strong>Llama 3</strong>。</li>
</ul>
<h3 id="74-mcpmodel-context-protocol">7.4 MCP（Model Context Protocol）协议<a class="headerlink" href="#74-mcpmodel-context-protocol" title="Permanent link">&para;</a></h3>
<p>MCP（<strong>Model Context Protocol</strong>，模型上下文协议）是由 <strong>Anthropic</strong> 在 <strong>2024年11月</strong> 推出的一种开放标准协议，旨在标准化大语言模型（LLM）与外部数据源、工具及服务之间的交互方式。MCP 的核心目标是解决 AI 生态中的 <strong>数据孤岛</strong> 和 <strong>工具接入碎片化</strong> 问题，让 AI 不仅能“说”，还能“做”——即直接调用外部工具执行任务，而不仅仅是生成文本。</p>
<p><img alt="img" src="assets/21c8e096-6645-469a-b537-3591c1abb483_944x733.jpg" /></p>
<p>MCP 协议通过标准化模型与外部资源的交互方式，提升 LLM 应用的功能性、灵活性和可扩展性。MCP 就像 USB-C 一样，可以让不同设备能够通过相同的接口连接在一起，如下图所示：</p>
<p><img alt="img" src="assets/https___dev-to-uploads.s3.amazonaws.com_uploads_articles_nuvybev34xhz3btc0xys.jpeg" /></p>
<p>MCP 架构主要包括三个核心组件：</p>
<ul>
<li><strong>MCP Host（主机）</strong>：如 Claude Desktop、Cursor 等 AI 应用，负责发起请求。</li>
<li><strong>MCP Server（服务器）</strong>：提供数据或工具接口（如 GitHub、Slack、数据库等），供 AI 调用。</li>
<li><strong>MCP Client（客户端）</strong>：接收用户指令，与 LLM 交互并执行 MCP 请求。</li>
</ul>
<h3 id="_1">小结总结<a class="headerlink" href="#_1" title="Permanent link">&para;</a></h3>
<ul>
<li>本小节主要介绍了LLM主流的开源大模型，对不同模型架构、训练目标、优缺点进行了分析和总结。</li>
</ul>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "..", "features": [], "search": "../assets/javascripts/workers/search.b8dbb3d2.min.js", "translations": {"clipboard.copied": "\u5df2\u590d\u5236", "clipboard.copy": "\u590d\u5236", "search.result.more.one": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.more.other": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 # \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.none": "\u6ca1\u6709\u627e\u5230\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.one": "\u627e\u5230 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.other": "# \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.placeholder": "\u952e\u5165\u4ee5\u5f00\u59cb\u641c\u7d22", "search.result.term.missing": "\u7f3a\u5c11", "select.version": "\u9009\u62e9\u5f53\u524d\u7248\u672c"}}</script>
    
    
      <script src="../assets/javascripts/bundle.081f42fc.min.js"></script>
      
        <script src="../js/extra.js"></script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML"></script>
      
    
  </body>
</html>